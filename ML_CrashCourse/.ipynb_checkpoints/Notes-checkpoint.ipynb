{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on ML Concepts\n",
    "### #Framing\n",
    "**Labels**: The target of the prediction <br>\n",
    "**Features**: Input variables used to train the model <br>\n",
    "$${\\{x_1, x_2, x_3,... x_N\\}}$$\n",
    "**Regression Model**: Predicts *continuous* values\n",
    "> ex: What is the value of _?<br>\n",
    "> ex: What is the probability that _?\n",
    "\n",
    "### #Descending into ML: Linear Regression\n",
    "**Classification Model**: Predicts *discrete* values <br>\n",
    "**Linear Regression**: $$y'=b+w_1x_1$$ $$y'=b+w_1x_1+w_2x_2+w_3x_3$$\n",
    "* $y'$ is the predicted label (a desired output).\n",
    "* $b$ is the bias (the y-intercept), sometimes referred to as $w_0$.\n",
    "* $w_1$ is the weight of feature 1. \n",
    "* $x_1$ is a feature (a known input).\n",
    "\n",
    "### #Descending into ML: Training and Loss\n",
    "**Mean square Error (MSE)**\n",
    "$$MSE=(1/N)\\sum_{(x,y)\\in D}{(y-prediction(x))^2}$$\n",
    "* $(x,y)$ is an example in which:\n",
    " * $x$ is the set of features.\n",
    " * $y$ is the example's label.\n",
    "* $prediction(x)$ is a function of the weights and bias in combination with the set features $x$.\n",
    "* D is a data set containing many labeled examples, which are $(x,y)$ pairs.\n",
    "* N is the number of examples in D.\n",
    "### #Reducting Loss:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
